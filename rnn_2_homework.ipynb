{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекуррентные нейросети 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequences(num_samples, seq_length):\n",
    "    data = []\n",
    "    for _ in range(num_samples):\n",
    "        x = np.random.randint(0, 10, size=seq_length)  \n",
    "        y = [x[0]]  \n",
    "        y += [(x[i] + x[0]) % 10 for i in range(1, seq_length)]  \n",
    "        data.append((x, y))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10000\n",
    "seq_length = 10\n",
    "data = generate_sequences(num_samples, seq_length)\n",
    "\n",
    "train_data = data[:8000]\n",
    "test_data = data[8000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = self.data[idx]\n",
    "        return torch.tensor(x, dtype=torch.long), torch.tensor(y, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SequenceDataset(train_data)\n",
    "test_dataset = SequenceDataset(test_data)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)  \n",
    "        self.rnn = nn.RNN(hidden_dim, hidden_dim, batch_first=True)  \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        out, _ = self.rnn(x)  \n",
    "        out = self.fc(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = 10  \n",
    "hidden_dim = 64 \n",
    "output_dim = 10  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleRNN(input_dim, hidden_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, test_loader, criterion, optimizer, num_epochs, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()\n",
    "        \n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "\n",
    "        for encrypted_seq, original_seq in train_loader:\n",
    "            encrypted_seq = encrypted_seq.to(device)\n",
    "            original_seq = original_seq.to(device)\n",
    "\n",
    "            output = model(encrypted_seq)\n",
    "            \n",
    "            output = output.view(-1, output.size(-1))  \n",
    "            original_seq = original_seq.view(-1)  \n",
    "\n",
    "            loss = criterion(output, original_seq)\n",
    "            train_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        model.eval()\n",
    "        test_loss = 0\n",
    "        test_correct = 0\n",
    "        test_total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for encrypted_seq, original_seq in test_loader:\n",
    "                encrypted_seq = encrypted_seq.to(device)\n",
    "                original_seq = original_seq.to(device)\n",
    "\n",
    "                output = model(encrypted_seq)\n",
    "\n",
    "                output = output.view(-1, output.size(-1))\n",
    "                original_seq = original_seq.view(-1)\n",
    "\n",
    "                loss = criterion(output, original_seq)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "        epoch_time = time.time() - start_time\n",
    "\n",
    "        print(f\"Ep [{epoch+1}/{num_epochs}], Time: {epoch_time:.2f} sec, Train Loss: {train_loss/len(train_loader):.4f}, Test Loss: {test_loss/len(test_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep [1/10], Time: 0.78 sec, Train Loss: 2.2184, Test Loss: 2.0397\n",
      "Ep [2/10], Time: 0.59 sec, Train Loss: 1.9304, Test Loss: 1.8489\n",
      "Ep [3/10], Time: 0.56 sec, Train Loss: 1.8242, Test Loss: 1.7824\n",
      "Ep [4/10], Time: 0.58 sec, Train Loss: 1.7630, Test Loss: 1.7202\n",
      "Ep [5/10], Time: 0.57 sec, Train Loss: 1.6830, Test Loss: 1.5530\n",
      "Ep [6/10], Time: 0.57 sec, Train Loss: 1.2098, Test Loss: 0.8805\n",
      "Ep [7/10], Time: 0.60 sec, Train Loss: 0.6816, Test Loss: 0.4638\n",
      "Ep [8/10], Time: 0.61 sec, Train Loss: 0.3289, Test Loss: 0.2213\n",
      "Ep [9/10], Time: 0.61 sec, Train Loss: 0.1848, Test Loss: 0.1345\n",
      "Ep [10/10], Time: 0.63 sec, Train Loss: 0.1096, Test Loss: 0.0877\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(model, sequence, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        sequence = torch.tensor(sequence, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        output = model(sequence)\n",
    "        predictions = torch.argmax(output, dim=2).squeeze(0).tolist()\n",
    "        return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вводная последовательность: [6 6 2 0 8 6 5 6 6 3]\n",
      "Предсказанная последовательность: [6, 2, 8, 6, 4, 2, 1, 2, 2, 9]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = np.random.randint(0, 10, size=10)  \n",
    "predicted_output = predict_sequence(model, test_sequence, device)\n",
    "\n",
    "print(f\"Вводная последовательность: {test_sequence}\")\n",
    "print(f\"Предсказанная последовательность: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)  \n",
    "        self.lstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True)  \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        out, _ = self.lstm(x)  \n",
    "        out = self.fc(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleLSTM(input_dim, hidden_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep [1/10], Time: 0.65 sec, Train Loss: 2.0432, Test Loss: 1.1965\n",
      "Ep [2/10], Time: 0.65 sec, Train Loss: 0.4239, Test Loss: 0.1089\n",
      "Ep [3/10], Time: 0.67 sec, Train Loss: 0.0604, Test Loss: 0.0344\n",
      "Ep [4/10], Time: 0.63 sec, Train Loss: 0.0243, Test Loss: 0.0175\n",
      "Ep [5/10], Time: 0.63 sec, Train Loss: 0.0136, Test Loss: 0.0107\n",
      "Ep [6/10], Time: 0.64 sec, Train Loss: 0.0087, Test Loss: 0.0072\n",
      "Ep [7/10], Time: 0.63 sec, Train Loss: 0.0061, Test Loss: 0.0052\n",
      "Ep [8/10], Time: 0.67 sec, Train Loss: 0.0044, Test Loss: 0.0039\n",
      "Ep [9/10], Time: 0.67 sec, Train Loss: 0.0034, Test Loss: 0.0030\n",
      "Ep [10/10], Time: 0.62 sec, Train Loss: 0.0026, Test Loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вводная последовательность: [9 9 7 2 3 0 0 3 6 2]\n",
      "Предсказанная последовательность: [9, 8, 6, 1, 2, 9, 9, 2, 5, 1]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = np.random.randint(0, 10, size=10)  \n",
    "predicted_output = predict_sequence(model, test_sequence, device)\n",
    "\n",
    "print(f\"Вводная последовательность: {test_sequence}\")\n",
    "print(f\"Предсказанная последовательность: {predicted_output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(SimpleGRU, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, hidden_dim)  \n",
    "        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)  \n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        out, _ = self.gru(x)  \n",
    "        out = self.fc(out)  \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleGRU(input_dim, hidden_dim, output_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep [1/10], Time: 0.64 sec, Train Loss: 2.1926, Test Loss: 1.9463\n",
      "Ep [2/10], Time: 0.53 sec, Train Loss: 1.0042, Test Loss: 0.2675\n",
      "Ep [3/10], Time: 0.52 sec, Train Loss: 0.1313, Test Loss: 0.0652\n",
      "Ep [4/10], Time: 0.56 sec, Train Loss: 0.0442, Test Loss: 0.0307\n",
      "Ep [5/10], Time: 0.60 sec, Train Loss: 0.0233, Test Loss: 0.0179\n",
      "Ep [6/10], Time: 0.57 sec, Train Loss: 0.0144, Test Loss: 0.0118\n",
      "Ep [7/10], Time: 0.56 sec, Train Loss: 0.0098, Test Loss: 0.0084\n",
      "Ep [8/10], Time: 0.58 sec, Train Loss: 0.0072, Test Loss: 0.0062\n",
      "Ep [9/10], Time: 0.58 sec, Train Loss: 0.0054, Test Loss: 0.0048\n",
      "Ep [10/10], Time: 0.62 sec, Train Loss: 0.0042, Test Loss: 0.0038\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    num_epochs=10,\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Вводная последовательность: [2 8 7 5 2 3 2 1 1 8]\n",
      "Предсказанная последовательность: [2, 0, 9, 7, 4, 5, 4, 3, 3, 0]\n"
     ]
    }
   ],
   "source": [
    "test_sequence = np.random.randint(0, 10, size=10)  \n",
    "predicted_output = predict_sequence(model, test_sequence, device)\n",
    "\n",
    "print(f\"Вводная последовательность: {test_sequence}\")\n",
    "print(f\"Предсказанная последовательность: {predicted_output}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mult_nn_net",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
